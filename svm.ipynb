{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,classification_report, confusion_matrix,average_precision_score\n",
    "\n",
    "df = pd.read_csv('data_banknote_authentication.txt',sep=\",\",names = ['Variance','Skewness','Curtosis','Entropy','Class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(x_train,y_train,x_test,y_test):\n",
    " #extracting features from each column of x_train array    \n",
    "    train_feature1 = x_train[:,0]\n",
    "    train_feature2 = x_train[:,1]\n",
    "    train_feature3 = x_train[:,2]\n",
    "    train_feature4 = x_train[:,3]\n",
    "#Reshape feature arrays to single column    \n",
    "    train_feature1 = train_feature1.reshape(len(x_train),1)\n",
    "    train_feature2 = train_feature2.reshape(len(x_train),1)\n",
    "    train_feature3 = train_feature3.reshape(len(x_train),1)\n",
    "    train_feature4 = train_feature4.reshape(len(x_train),1)\n",
    "#Return features    \n",
    "    return train_feature1,train_feature2,train_feature3,train_feature4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeWeights(x_train):\n",
    "#Initial weights as per number of features. 4 in this case    \n",
    "    weight1 = np.zeros((len(x_train),1))\n",
    "    weight2 = np.zeros((len(x_train),1))\n",
    "    weight3 = np.zeros((len(x_train),1))\n",
    "    weight4 = np.zeros((len(x_train),1))\n",
    "    \n",
    "    return weight1,weight2,weight3,weight4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataframeToArray(x_train,y_train,x_test,y_test):\n",
    "    #Convert dataframe to array using numpy   \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "#Convert Y train and test dataframe to single column    \n",
    "    y_train = y_train.reshape(len(y_train),1)\n",
    "    y_test = y_test.reshape(len(y_test),1)\n",
    "    \n",
    "    return x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear_optimizer(y_train,w1,w2,w3,w4,feature1,feature2,feature3,feature4,iterations, learningRate):\n",
    "    epoch = 1\n",
    "#    alpha = 0.001\n",
    "#    \n",
    "    while(epoch < iterations):\n",
    "        y = w1 * feature1 + w2 * feature2 +  w3 * feature3 + w4 * feature4\n",
    "        prod = y * y_train\n",
    "        print(epoch)\n",
    "        i = 0\n",
    "        for val in prod:\n",
    "            if(val >= 1):\n",
    "                cost = 0\n",
    "                w1 = w1 - learningRate * (2 * 1/epoch * w1)\n",
    "                w2 = w2 - learningRate * (2 * 1/epoch * w2)\n",
    "                w3 = w3 - learningRate * (2 * 1/epoch * w3)\n",
    "                w4 = w4 - learningRate * (2 * 1/epoch * w4)\n",
    "                \n",
    "            else:\n",
    "                cost = 1 - val \n",
    "                w1 = w1 + learningRate * (feature1[i] * y_train[i] - 2 * 1/epoch * w1)\n",
    "                w2 = w2 + learningRate * (feature2[i] * y_train[i] - 2 * 1/epoch * w2)\n",
    "                w3 = w3 + learningRate * (feature3[i] * y_train[i] - 2 * 1/epoch * w3)\n",
    "                w4 = w4 + learningRate * (feature4[i] * y_train[i] - 2 * 1/epoch * w4)\n",
    "            i += 1\n",
    "        epoch += 1\n",
    "    return w1,w2,w3,w4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(x_train,y_train,x_test,y_test,iterations,alpha,d,gamma):\n",
    "\n",
    "    print(\"Feature Extraction\\n\")\n",
    "    feature1,feature2,feature3,feature4  = extractFeatures(x_train,y_train,x_test,y_test)\n",
    "    print(\"Weight Initialization\\n\")\n",
    "    w1,w2,w3,w4 = initializeWeights(x_train)\n",
    "    print(\"Weight Optimizer\\n\")\n",
    "    \n",
    "    ow1,ow2,ow3,ow4 = Linear_optimizer(y_train,w1,w2,w3,w4,feature1,feature2,feature3,feature4,iterations,alpha)\n",
    "    return ow1,ow2,ow3,ow4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMpredict(w1,w2,w3,w4,d,gamma):\n",
    "\n",
    "#Resize the weights wrt to testing data \n",
    "#Remoev extra indexes    \n",
    "    index = list(range(len(x_test),len(x_train)))\n",
    "    w1 = np.delete(w1,index)\n",
    "    w2 = np.delete(w2,index)\n",
    "    w3 = np.delete(w3,index)\n",
    "    w4 = np.delete(w4,index)\n",
    "#Reshape weights array w.r.t testing data    \n",
    "    w1 = w1.reshape(len(x_test),1)\n",
    "    w2 = w2.reshape(len(x_test),1)\n",
    "    w3 = w3.reshape(len(x_test),1)\n",
    "    w4 = w4.reshape(len(x_test),1)\n",
    "\n",
    "#Extract features from testing data\n",
    "    test_f1 = x_test[:,0]\n",
    "    test_f2 = x_test[:,1]\n",
    "    test_f3 = x_test[:,2]\n",
    "    test_f4 = x_test[:,3]\n",
    "#Reshaping the testing features wrt testing data    \n",
    "    test_f1 = test_f1.reshape(len(x_test),1)\n",
    "    test_f2 = test_f2.reshape(len(x_test),1)\n",
    "    test_f3 = test_f3.reshape(len(x_test),1)\n",
    "    test_f4 = test_f4.reshape(len(x_test),1)\n",
    "    \n",
    "    \n",
    "    y_predicted = w1 * test_f1 + w2 * test_f2 + w3 * test_f3 + w4 * test_f4\n",
    "    \n",
    "    allPredictions = []\n",
    "    for val in y_predicted:\n",
    "        if(val > 1):\n",
    "            allPredictions.append(1)\n",
    "        else:\n",
    "            allPredictions.append(-1)\n",
    "    \n",
    "    print(\"ACCURACY for : \",accuracy_score(y_test,allPredictions))\n",
    "\n",
    "    print(\"CLASSIFICATION REPORT: \",classification_report(y_test,allPredictions))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction\n",
      "\n",
      "Weight Initialization\n",
      "\n",
      "Weight Optimizer\n",
      "\n",
      "1\n",
      "ACCURACY for :  0.26181818181818184\n",
      "CLASSIFICATION REPORT:                precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.00      0.00      0.00       155\n",
      "           1       0.81      0.60      0.69       120\n",
      "\n",
      "    accuracy                           0.26       275\n",
      "   macro avg       0.27      0.20      0.23       275\n",
      "weighted avg       0.35      0.26      0.30       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = df.drop(['Class'], axis=1) , df.Class\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y,test_size=0.20, random_state=33)\n",
    "x_train, y_train, x_test, y_test = DataframeToArray(x_train, y_train, x_test, y_test)\n",
    "feature1,feature2,feature3,feature4  = extractFeatures(x_train,y_train,x_test,y_test)\n",
    "\n",
    "itr = 2\n",
    "lr = 0.2\n",
    "d = 1 \n",
    "g =1 \n",
    "w1,w2,w3,w4 = SVM(x_train,y_train,x_test,y_test,itr,lr,d,g)\n",
    "SVMpredict(w1,w2,w3,w4,d,g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
